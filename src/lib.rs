//! # bed2gtf
//! A Rust BED-to-GTF translator.
//!
//! ## Overview
//! `bed2gtf` is a Rust-based utility designed to facilitate
//! the conversion of BED files to GTF files. This tool offers
//! good performance and quick results, making it, filling a
//! gap in the current landscape of BED-to-GTF converters.
//! The main objective of `bed2gtf` is to streamline the process of
//! translating genomic data from the BED format to the GTF format,
//! enabling easier downstream analysis.
//!
//!
//! ## Usage
//!
//! ### Installation
//!
//! `bed2gtf` can be easily installed and used on your system.
//! Detailed installation instructions are available
//! on the [GitHub repository](https://github.com/alejandrogzi/bed2gtf).
//!
//! ### Conversion
//!
//! To convert a BED file to a GTF file using `bed2gtf`, you can use the
//! following command:
//!
//! ```shell
//! bed2gff input.bed isoforms.txt output.gtf
//! ```
//!
//! Where:
//! - `input.bed` is the input BED file you want to convert.
//! - `isoforms.txt` is a file that contains information about isoforms.
//! - `output.gff3` is the output GTF file where the conversion results
//! will be stored.
//!
//! ## Output
//!
//! `bed2gtf` produces GTF files compliant with the GTF3 standard.
//! The resulting GFF file contains detailed annotations of genomic
//! features, including genes, transcripts, exons, coding
//! sequences (CDS), start codons, and stop codons.
//!
//! ## Example
//!
//! Here is an example of a GTF header generated by `bed2gtf`:
//!
//! ```plaintext
//! #provider: bed2gtf
//! #version: 1.7.0
//! #contact: github.com/alejandrogzi/bed2gtf
//! #date: YYYY-MM-DD
//! ```
//!
//! ## Contact and Support
//!
//! For inquiries, bug reports, or suggestions, please
//! visit the [GitHub repository](https://github.com/alejandrogzi/bed2gtf).
//! We welcome your feedback and contributions to enhance this tool.

use std::collections::HashMap;
use std::error::Error;
use std::fs::File;
use std::io::{self, BufWriter, Read, Write};
use std::time::Instant;

use colored::Colorize;
use peak_alloc::PeakAlloc;

use log::Level;

use chrono::Datelike;

use indoc::indoc;

use natord::compare;

use rayon::prelude::*;

mod bed;
use bed::BedRecord;

mod codon;
use codon::*;

pub mod lines;
use lines::*;

const SOURCE: &str = "bed2gtf";
const VERSION: &str = "1.8.0";
const REPOSITORY: &str = "github.com/alejandrogzi/bed2gtf";

#[global_allocator]
static PEAK_ALLOC: PeakAlloc = PeakAlloc;

/// Convert a BED file to a GTF file.
/// ```
/// use bed2gtf::bed2gtf;
/// bed2gtf("input.bed", "isoforms.txt", "output.gtf");
/// ```
pub fn bed2gtf(input: &String, isoforms: &String, output: &String) -> Result<(), Box<dyn Error>> {
    msg();
    simple_logger::init_with_level(Level::Info)?;

    let start = Instant::now();

    let isf = reader(isoforms).unwrap();
    let bed = bed_reader(input);
    let isoforms = get_isoforms(&isf);
    let gene_track = custom_par_parse(&bed).unwrap();
    let coords = combine_maps_par(&isoforms, &gene_track);
    let results: Vec<_> = bed
        .par_iter()
        .map(|record| to_gtf(&record, &isoforms))
        .collect();

    let flat_results: Vec<_> = results.into_iter().flatten().collect();
    let mut combined = [coords, flat_results].concat();

    combined.par_sort_unstable_by(|a, b| {
        let chr_cmp = compare(&a.0, &b.0);
        if chr_cmp == std::cmp::Ordering::Equal {
            a.2.cmp(&b.2)
        } else {
            chr_cmp
        }
    });

    let output = File::create(output).unwrap();
    let mut writer = BufWriter::new(output);
    comments(&mut writer);

    for (chrom, gene_type, start, end, strand, phase, attr) in combined {
        let gtf_line = format!(
            "{}\t{}\t{}\t{}\t{}\t.\t{}\t{}\t{}\n",
            chrom, SOURCE, gene_type, start, end, strand, phase, attr
        );
        writer.write_all(gtf_line.as_bytes()).unwrap();
    }

    let peak_mem = PEAK_ALLOC.peak_usage_as_mb();

    log::info!("Memory usage: {} MB", peak_mem);
    log::info!("Elapsed: {:.4?} secs", start.elapsed().as_secs_f32());

    Ok(())
}

fn to_gtf(
    bedline: &BedRecord,
    isoforms: &HashMap<String, String>,
) -> Vec<(String, String, u32, u32, String, String, String)> {
    let mut result: Vec<(String, String, u32, u32, String, String, String)> = Vec::new();
    let gene = isoforms.get(&bedline.name).unwrap();
    let fcodon = first_codon(bedline).unwrap();
    let lcodon = last_codon(bedline).unwrap();
    let first_utr_end = bedline.cds_start;
    let last_utr_start = bedline.cds_end;
    let frames = bedline.get_frames();

    let cds_end: u32 = if bedline.strand == "+" && codon_complete(&lcodon) {
        move_pos(bedline, lcodon.end, -3)
    } else {
        bedline.cds_end
    };

    let cds_start = if bedline.strand == "-" && codon_complete(&fcodon) {
        move_pos(bedline, fcodon.start, 3)
    } else {
        bedline.cds_start
    };

    build_gtf_line(
        bedline,
        gene,
        "transcript",
        bedline.tx_start,
        bedline.tx_end,
        3,
        -1,
        &mut result,
    );

    for i in 0..bedline.exon_count as usize {
        build_gtf_line(
            bedline,
            gene,
            "exon",
            bedline.exon_start[i],
            bedline.exon_end[i],
            3,
            i as i16,
            &mut result,
        );
        if cds_start < cds_end {
            write_features(
                i,
                bedline,
                gene,
                first_utr_end,
                cds_start,
                cds_end,
                last_utr_start,
                frames[i] as u32,
                &mut result,
            );
        }
    }

    if bedline.strand != "-" {
        if codon_complete(&fcodon) {
            write_codon(bedline, gene, "start_codon", fcodon, &mut result);
        }
        if codon_complete(&lcodon) {
            write_codon(bedline, gene, "stop_codon", lcodon, &mut result);
        }
    } else {
        if codon_complete(&lcodon) {
            write_codon(bedline, gene, "start_codon", lcodon, &mut result);
        }
        if codon_complete(&fcodon) {
            write_codon(bedline, gene, "stop_codon", fcodon, &mut result);
        }
    }

    result
}

fn move_pos(record: &BedRecord, pos: u32, dist: i32) -> u32 {
    let mut pos = pos;
    assert!(record.tx_start <= pos && pos <= record.tx_end);

    let mut exon_index = record
        .exon_start
        .iter()
        .zip(record.exon_end.iter())
        .position(|(start, end)| pos >= *start && pos <= *end)
        .unwrap_or_else(|| {
            let message = format!("Position {} not in exons.", pos);
            panic!("{}", message);
        }) as i16;

    let mut steps = dist.abs();
    let direction = if dist >= 0 { 1 } else { -1 };

    while steps > 0 {
        let (exon_start, exon_end) = (
            record.exon_start[exon_index as usize],
            record.exon_end[exon_index as usize],
        );

        if pos >= exon_start && pos <= exon_end {
            pos += direction as u32;
            steps -= 1;
        } else if direction >= 0 {
            exon_index += 1;
            if (exon_index as usize) < record.exon_count as usize {
                pos = record.exon_start[exon_index as usize];
            }
        } else {
            exon_index -= 1;
            if exon_index >= 0 {
                pos = record.exon_end[exon_index as usize] - 1;
                steps -= 1;
            }
        }
    }
    if steps > 0 {
        panic!("can't move {} by {}", pos, dist);
    }
    pos
}

fn bed_reader(file: &String) -> Vec<BedRecord> {
    let bed = reader(file).unwrap();
    let records = parallel_parse(&bed).unwrap();
    records
}

fn get_isoforms(file: &String) -> HashMap<String, String> {
    let pairs = parallel_hash_rev(file);
    // let rev_pairs = parallel_hash(&file);

    if pairs.len() == 0 {
        println!(
            "{} {}",
            "Fail:".bright_red().bold(),
            "BED file could not be converted. Please check your isoforms file."
        );
        std::process::exit(1);
    }
    // (pairs, rev_pairs)
    pairs
}

fn reader(file: &str) -> io::Result<String> {
    let mut file = File::open(file)?;
    let mut contents = String::new();
    file.read_to_string(&mut contents)?;
    Ok(contents)
}

fn parallel_hash<'a>(s: &'a str) -> HashMap<String, String> {
    s.par_lines()
        .filter_map(|line| {
            let mut words = line.split_whitespace();
            if let Some(fw) = words.next() {
                if let Some(sw) = words.next() {
                    return Some((fw.to_owned(), sw.to_owned()));
                }
            }
            // If the line doesnâ€™t have two words, ignore it and return None.
            None
        })
        .collect()
}

fn parallel_hash_rev<'a>(s: &'a str) -> HashMap<String, String> {
    s.par_lines()
        .filter_map(|line| {
            let mut words = line.split_whitespace();
            if let Some(fw) = words.next() {
                if let Some(sw) = words.next() {
                    return Some((sw.to_owned(), fw.to_owned()));
                }
            }
            None
        })
        .collect()
}

fn parallel_parse<'a>(s: &'a str) -> Result<Vec<BedRecord>, &'static str> {
    let mut records: Result<Vec<BedRecord>, &'static str> =
        s.par_lines().map(|line| BedRecord::parse(line)).collect();

    records
}

fn custom_par_parse(
    records: &Vec<BedRecord>,
) -> Result<HashMap<String, (String, u32, u32, String)>, &'static str> {
    let gene_coordinates = records
        .into_par_iter()
        .fold(
            || HashMap::new(),
            |mut acc: HashMap<String, (String, u32, u32, String)>, record| {
                let entry = acc.entry(record.name.clone()).or_insert((
                    record.chrom.clone(),
                    record.tx_start,
                    record.tx_end,
                    record.strand.clone(),
                ));
                acc
            },
        )
        .reduce(
            || HashMap::new(),
            |mut a: HashMap<String, (String, u32, u32, String)>, b| {
                for (key, (chrom, start, end, strand)) in b {
                    let entry = a.entry(key).or_insert((chrom, start, end, strand));
                }
                a
            },
        );
    Ok(gene_coordinates)
}

fn combine_maps_par(
    isoforms_to_genes: &HashMap<String, String>,
    transcript_coordinates: &HashMap<String, (String, u32, u32, String)>,
) -> Vec<(String, String, u32, u32, String, String, String)> {
    let coords = isoforms_to_genes
        .par_iter()
        .fold(
            || HashMap::new(),
            |mut acc: HashMap<String, (String, u32, u32, String)>, (transcript, gene)| {
                if let Some(&(ref chrom, start, end, ref strand)) =
                    transcript_coordinates.get(transcript)
                {
                    let entry = acc.entry(gene.clone()).or_insert((
                        chrom.to_string(),
                        start,
                        end,
                        strand.to_string(),
                    ));
                    entry.1 = entry.1.min(start); // Update min start
                    entry.2 = entry.2.max(end); // Update max end
                }
                acc
            },
        )
        .reduce(
            || HashMap::new(),
            |mut a, b| {
                for (gene, (chrom, start, end, strand)) in b {
                    let entry = a.entry(gene).or_insert((chrom, start, end, strand));
                    entry.1 = entry.1.min(start); // Update min start
                    entry.2 = entry.2.max(end); // Update max end
                }
                a
            },
        );

    let lines = coords
        .par_iter()
        .map(|(gene, (chrom, start, end, strand))| {
            (
                chrom.to_string(),
                "gene".to_string(),
                start + 1,
                *end,
                strand.to_string(),
                ".".to_string(),
                format!("gene_id \"{}\";", gene),
            )
        })
        .collect();
    lines
}

fn msg() {
    println!(
        "{}\n{}",
        "\n##### BED2GTF #####".bright_cyan().bold(),
        indoc!(
            "A fast BED-to-GTF converter written in Rust.
        Repository: https://github.com/alejandrogzi/bed2gtf
        Feel free to contact the developer if any issue/suggest/bug is found.
        "
        )
    );
}

fn get_date() -> String {
    let now = chrono::Utc::now();
    let year = now.year();
    let month = now.month();
    let day = now.day();

    format!("{}-{}-{}", year, month, day)
}

fn comments(file: &mut BufWriter<File>) {
    let _ = file.write_all(format!("#provider: {}\n", SOURCE).as_bytes());
    let _ = file.write_all(format!("#version: {}\n", VERSION).as_bytes());
    let _ = file.write_all(format!("#contact: {}\n", REPOSITORY).as_bytes());
    let _ = file.write_all(format!("#date: {}\n", get_date()).as_bytes());
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::io::Read;

    fn make_bed_test_file(content: &str) -> Result<String, Box<dyn Error>> {
        let mut file = File::create("test.bed")?;
        file.write_all(content.as_bytes())?;

        Ok("test.bed".to_string())
    }

    fn make_isoforms_test_file(content: &str) -> Result<String, Box<dyn Error>> {
        let mut file = File::create("test.isoforms")?;
        file.write_all(content.as_bytes())?;

        Ok("test.isoforms".to_string())
    }

    fn teardown(files: Vec<String>) {
        for file in files {
            std::fs::remove_file(file).unwrap();
        }
    }

    #[test]
    fn main_test() {
        let input = make_bed_test_file(
            "chr15\t81000922\t81005788\tENST00000267984\t0\t+\t81002271\t81003360\t0\t1\t4866,\t0,",
        )
        .unwrap();

        let isoforms = make_isoforms_test_file(indoc!(
            "ENSG00000140406\tENST00000267984
        ENSG00000140545\tENST00000560937
        ENSG00000082438\tENST00000495084"
        ))
        .unwrap();

        let output = "out.gtf".to_string();

        let _ = bed2gtf(&input, &isoforms, &output).unwrap();
        let mut file = File::open(output.clone()).unwrap();
        let mut contents = String::new();
        file.read_to_string(&mut contents).unwrap();

        let converted_content = indoc!("chr15\tbed2gtf\tgene\t81000923\t81005788\t.\t+\t.\tgene_id \"ENSG00000140406\";
        chr15\tbed2gtf\ttranscript\t81000923\t81005788\t.\t+\t.\tgene_id \"ENSG00000140406\"; transcript_id \"ENST00000267984\";
        chr15\tbed2gtf\texon\t81000923	81005788\t.\t+\t.\tgene_id \"ENSG00000140406\"; transcript_id \"ENST00000267984\"; exon_number \"1\"; exon_id \"ENST00000267984.1\";
        chr15\tbed2gtf\tfive_prime_utr\t81000923\t81002271\t.\t+\t0\tgene_id \"ENSG00000140406\"; transcript_id \"ENST00000267984\";
        chr15\tbed2gtf\tCDS	81002272\t81003357\t.\t+\t0\tgene_id \"ENSG00000140406\"; transcript_id \"ENST00000267984\"; exon_number \"1\"; exon_id \"ENST00000267984.1\";
        chr15\tbed2gtf\tthree_prime_utr\t81003361\t81005788\t.\t+\t0\tgene_id \"ENSG00000140406\"; transcript_id \"ENST00000267984\";
        chr15\tbed2gtf\tstart_codon\t81002272\t81002274\t.\t+\t0\tgene_id \"ENSG00000140406\"; transcript_id \"ENST00000267984\"; exon_number \"1\"; exon_id \"ENST00000267984.1\";
        chr15\tbed2gtf\tstop_codon\t81003358\t81003360\t.\t+\t0\tgene_id \"ENSG00000140406\"; transcript_id \"ENST00000267984\"; exon_number \"1\"; exon_id \"ENST00000267984.1\";\n");

        assert_eq!(contents, converted_content);

        teardown(vec![input, isoforms, output]);
    }
}
